{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42834217",
   "metadata": {},
   "source": [
    "# Exercise on Regression\n",
    "\n",
    "## Exercise 1: Linear Regression on Cancer-Data\n",
    "\n",
    "### Least-Square, Lasso, Ridge and PCR regression on Cancer Data\n",
    "\n",
    "In this exercise we'll check the difference in the application of different regression algorithms.\n",
    "\n",
    "The **goal** is **to predict** the association between **prostate specific antigen (PSA)** and several **clinical measures** that are potentially associated with PSA in men who were about to receive a radical prostatectomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b988fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48c28e",
   "metadata": {},
   "source": [
    "## Import, preprocess and visualize the data\n",
    "\n",
    "The cancer data presents information about the clinical measures of men before a prostatectomy and the results of the prostatectomy:\n",
    "\n",
    "- Target:\n",
    "    - lpsa: log PSA score (This can be read by a doctor to assess the risk of prostate cancer)\n",
    "- Measurements:\n",
    "    - lcavol: log cancer volume\n",
    "    - lweight: log prostate weight\n",
    "    - age: age of patient\n",
    "    - lbph: log of the amount of benign prostatic hyperplasia\n",
    "    - svi: seminal vesicle invasion\n",
    "    - lcp: log of capsular penetration\n",
    "    - gleason: Gleason score\n",
    "    - pgg45: percent of Gleason scores 4 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dceaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cancer_data.txt', sep='\\t', index_col=0) # The entire dataset\n",
    "X = np.array(data.iloc[:,:-2]) # Matrix of the features\n",
    "y = np.array(data.iloc[:,-2]) # Matrix of the target\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b53b7",
   "metadata": {},
   "source": [
    "### Preprocess and visualize\n",
    "\n",
    "We need to preprocess the data. \n",
    "\n",
    "**To do**:\n",
    "    \n",
    "- Preprocess the data : \n",
    "    - Split the dataset in train and test data. Test should be at least 20% of the total dataset size\n",
    "    - Center and scale\n",
    "- Visualize the scaled data: Target Vs Measurements\n",
    "    \n",
    "**Hint:** \n",
    "\n",
    "- To split the dataset, use the function train_test_split (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- To center and scale, use the function StandardScaler (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## create the test and train datasets\n",
    "# ...\n",
    "\n",
    "## scale and center the data\n",
    "# ...\n",
    "\n",
    "# X_std_...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the next lines to visualize the target VS the first measurements\n",
    "\n",
    "# Nmeas = 4\n",
    "# fig, axs = plt.subplots(1,Nmeas, figsize=(Nmeas*3,3))\n",
    "# for i in range(Nmeas):\n",
    "#     axs[i].scatter(X_std_train[:,i], y_train, label = 'train')\n",
    "#     axs[i].scatter(X_std_test[:,i], y_test, c='r', alpha=0.5, label='test')\n",
    "#     axs[i].set_xlabel(str(X_name[i] + '$_{std}$') )\n",
    "#     axs[i].set_ylabel(y_name)\n",
    "# axs[Nmeas-1].legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254607",
   "metadata": {},
   "source": [
    "## Least-Squares regression\n",
    "\n",
    "The objective function of a least-squares problem $ y \\approx f(X) = \\beta X$ is:\n",
    "\n",
    "$\\hat{\\beta}^{LS} = \\textit{argmin}\\{ || y - f(X) ||^2 \\} = \\textit{argmin}\\{ || y -  \\beta X ||^2 \\} $ \n",
    "\n",
    "\n",
    "- **To do:**\n",
    "    - use the function `LinearRegression` to fit the regression model to the data.\n",
    "    - Plot the prediction and test on the measurement-target space\n",
    "    - Plot the predicted values against the observed ones (parity plot).\n",
    "\n",
    "- **Hint:**\n",
    "    - The function documentation is in: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "    - A simple user guide on the different linear regression models can be found here: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Create the linear regression object\n",
    "# LS_reg = ...\n",
    "\n",
    "## Predict the y_test from the test measurements\n",
    "# y_pred_LS = ...\n",
    "\n",
    "## Calculate LS R2 score\n",
    "# LS_score = ...\n",
    "\n",
    "## Plot the prediction and test on the measurement-target space\n",
    "# ...\n",
    "\n",
    "## Parity plot:  predicted values agains the test values \n",
    "\n",
    "# plt.figure(figsize=(3,3))\n",
    "# plt.title('Parity plot')\n",
    "###  ...\n",
    "# plt.xlim(y_test.min()-1, y_test.max()+1)\n",
    "# plt.ylim(y_test.min()-1, y_test.max()+1)\n",
    "# plt.xlabel('Observed log PSA')\n",
    "# plt.ylabel('Predicted log PSA')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31db41",
   "metadata": {},
   "source": [
    "## Lasso regression\n",
    "\n",
    "The objective function of a least-squares problem $ y \\approx f(X) = \\beta X$ is:\n",
    "\n",
    "$\\hat{\\beta}^{Lasso} = \\textit{argmin}\\{ || y -  \\beta X ||^2 +  \\alpha ||\\beta||_1 \\}  $ \n",
    "\n",
    "\n",
    "- **To do:**\n",
    "    - use the function `Lasso` to fit the regression model to the data (Use your choice for the `alpha` parameter)\n",
    "    - Compare LS and Lasso: weights and R2 of the regression.\n",
    "    - Which `alpha` would you choose?\n",
    "\n",
    "- **Hint:**\n",
    "    - The function documentation is in: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5a07e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "## Create the Lasso object\n",
    "# Lasso_reg   = ...\n",
    "\n",
    "## Predict the y_test from the test measurements\n",
    "# y_pred_Lasso = ...\n",
    "\n",
    "## Compute the score\n",
    "# Lasso_score = ...\n",
    "\n",
    "# print(f'LS coefficients  :  {np.round(LS_reg.coef_, 3)}')\n",
    "# print(f'Lasso coefficients: {np.round(Lasso_reg.coef_, 3)}')\n",
    "# print('')\n",
    "\n",
    "# print('LS score:    ' + str(np.round(LS_score,2)))\n",
    "# print('Lasso score: ' + str(np.round(Lasso_score,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b2a1a",
   "metadata": {},
   "source": [
    "Comparative plots LS-Lasso at different alphas. \n",
    "\n",
    "- **To do:**\n",
    "    - Uncomment the following lines \n",
    "    - Select the \"alphas\" desired to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comparative plots LS- Lasso at different \n",
    "\n",
    "# alphas = [0.01, 0.1, 0.3, 0.5, 0.7, 1]\n",
    "# n_alpha= len(alphas)\n",
    "# colors = plt.cm.gray(np.linspace(0, 0.9, n_alpha))\n",
    "\n",
    "# # Coefficients plot\n",
    "# n_coef = len(LS_reg.coef_)\n",
    "# Lasso_coefs = np.zeros((n_alpha, n_coef))\n",
    "# Lasso_scores = np.zeros((n_alpha, 1))\n",
    "\n",
    "\n",
    "# for i, alpha in enumerate(alphas):\n",
    "#     # Create the Lasso Regression object\n",
    "#     Lasso_reg = Lasso(alpha= alpha).fit(X_std_train, y_train)\n",
    "\n",
    "#     # Predict the y_test from the test measurements\n",
    "#     y_pred_Lasso = Lasso_reg.predict(X_std_test)\n",
    "\n",
    "#     # Save coefficients\n",
    "#     Lasso_coefs[i,:] = Lasso_reg.coef_\n",
    "    \n",
    "#     # Compute and save R2 scores\n",
    "#     Lasso_score = Lasso_reg.score(X_std_test, y_test)\n",
    "#     Lasso_scores[i]=Lasso_score\n",
    "    \n",
    "\n",
    "# # Coefficients Plot\n",
    "# plt.figure(figsize=(10,3))\n",
    "# plt.scatter(range(n_coef),LS_reg.coef_   , label='LS')\n",
    "# for i, alpha in enumerate(alphas):\n",
    "#     plt.scatter(range(n_coef),Lasso_coefs[i,:], color=colors[i],\n",
    "#                 label=r'$\\alpha$ = ' +str(alpha), alpha=0.5, edgecolor='k')\n",
    "\n",
    "# plt.xlabel('i')\n",
    "# plt.ylabel(r'$\\beta_i$')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Score Plot\n",
    "# plt.figure(figsize=(10,3))\n",
    "# plt.plot([0,1], LS_score*np.array([1,1])    , label='LS')\n",
    "# plt.plot(alphas, Lasso_scores , '-', c='k' , label='Lasso')\n",
    "# plt.scatter(alphas, Lasso_scores , c=colors , edgecolor='k')\n",
    "\n",
    "# plt.xlabel(r'$\\alpha$')\n",
    "# plt.ylabel('R2 score')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df6770",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "The penalty on the L1 norm is used to promote the sparsity of the regression weights.\n",
    "- Higher `alpha` -> Simpler model (More sparse)\n",
    "- Lower  `alpha` -> More complex model but it may overfit\n",
    "\n",
    "To infer the **optimum** value of $\\alpha$ to apply we can use the **cross-validation**:\n",
    "\n",
    "- **To do:**\n",
    "    - use the function LassoCV to fit the regression model to the data.\n",
    "    - Parity plot \n",
    "    - Compare the LassoCV alpha parameter to the one you selected in the exercise before.\n",
    "\n",
    "- **Hint:**\n",
    "    - The function documentation is in: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\n",
    "    - Use the function's attribute to obtain the optimal alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3e6a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "## Create the Lasso CV object\n",
    "# LassoCV_reg = ...\n",
    "\n",
    "## Predict the y_test from the test measurements\n",
    "# y_pred_LassoCV = ...\n",
    "\n",
    "## Compute the score\n",
    "# LassoCV_score = ...\n",
    "\n",
    "## Display the results\n",
    "# print(f'LS      coefficients: {np.round(LS_reg.coef_, 3)}')\n",
    "# print(f'LassoCV coefficients: {np.round(LassoCV_reg.coef_, 3)}')\n",
    "# print('')\n",
    "\n",
    "# print('LS      score: ' + str(np.round(LS_score,2)))\n",
    "# print('LassoCV score: ' + str(np.round(LassoCV_score,2)))\n",
    "# print('')\n",
    "# print('LassoCV alpha: ' + str(np.round(LassoCV_reg.alpha_,4)))\n",
    "\n",
    "\n",
    "## Parity Plot\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aaec55",
   "metadata": {},
   "source": [
    "## RidgeCV regression \n",
    "\n",
    "The objective function of a least-squares problem $ y \\approx f(X) = \\beta X$ is:\n",
    "\n",
    "$\\hat{\\beta}^{Ridge} = \\textit{argmin}\\{ || y -  \\beta X ||^2 +  \\alpha ||\\beta||_2^2 \\}  $ \n",
    "\n",
    "\n",
    "- **To do:**\n",
    "    - Use the function `RidgeCV` to fit the regression model.\n",
    "    - Compare LS and RidgeCV: weights and R2 of the regression.\n",
    "    - Parity Plot\n",
    "\n",
    "- **Hint:**\n",
    "    - The function documentation is in: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# # Create the Ridge CV object\n",
    "# RidgeCV_reg = ...\n",
    "\n",
    "# # Predict the y_test from the test measurements\n",
    "# y_pred_RidgeCV =...\n",
    "\n",
    "# # Compute the score\n",
    "# RidgeCV_score = ...\n",
    "\n",
    "# # Display the results\n",
    "# print(f'LS      coefficients: {np.round(LS_reg.coef_, 3)}')\n",
    "# print(f'RidgeCV coefficients: {np.round(RidgeCV_reg.coef_, 3)}')\n",
    "# print('')\n",
    "\n",
    "# print('LS      score: ' + str(np.round(LS_score,2)))\n",
    "# print('RidgeCV score: ' + str(np.round(RidgeCV_score,2)))\n",
    "# print('')\n",
    "# print('RidgeCV alpha: ' + str(np.round(RidgeCV_reg.alpha_,4)))\n",
    "\n",
    "\n",
    "# # Parity Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f638b65",
   "metadata": {},
   "source": [
    "## Principal Components Regression (PCR)\n",
    "\n",
    "Principal Components Regression consist on perfoming a linear regression (Least-Squares) on the PCs of the data. \n",
    "\n",
    "That is, the regression is performed in the projection of the data into the PCA basis: $\\boldsymbol{Z}= \\boldsymbol{XA}$\n",
    "\n",
    "The regression problem is transformed:\n",
    " - from: finding $\\beta$ in $ y \\approx f(X) = \\beta X$ \n",
    " - to:   finding $\\gamma$ in $ y \\approx f(Z) = \\gamma Z$ \n",
    " \n",
    "Therefore, the first step is performing PCA and then, regress $y$ knowing $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcf891",
   "metadata": {},
   "source": [
    "- **To do:**\n",
    "    - Perform PCA. \n",
    "    - CAlculate the PC matrix ($A$) and the PC score matrix ($Z$)\n",
    "    - Plot the explained variance ratio\n",
    "    - Questions to reply:\n",
    "        - In which dataset should we perfomed the PCA? \n",
    "        - How many PCs should we retain?\n",
    "- **Hint:**\n",
    "    - The function documentation is in: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf3065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Perform the PCA\n",
    "# pca = ...\n",
    "\n",
    "# # PC matrix and PC score matrices: A , Z_train, Z_test\n",
    "# ...\n",
    "\n",
    "# # Plot the explained variance ratio\n",
    "# plt.figure(figsize=(3,3))\n",
    "# ...\n",
    "# plt.xlabel('PC number')\n",
    "# plt.ylabel('explained variance ratio')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea473c",
   "metadata": {},
   "source": [
    "- **To do:**\n",
    "    - Build the PCR: Linear Regression: Z -> y\n",
    "    - Compare LS and PCR: weights and R2 of the regression.\n",
    "    - Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5b376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Build the PCR: Linear Regression: Z-> y\n",
    "# PCR_reg = ...\n",
    "\n",
    "# # Predict the y_test from the test measurements\n",
    "# y_pred_PCR = ...\n",
    "\n",
    "# # Compute the score\n",
    "# PCR_score = ...\n",
    "\n",
    "\n",
    "# # Display the results\n",
    "# print(f'LS  coefficients: {np.round(LS_reg.coef_, 3)}')\n",
    "# print(f'PCR coefficients: {np.round(PCR_reg.coef_, 3)}')\n",
    "# print('')\n",
    "\n",
    "# print('LS  score: ' + str(np.round(LS_score,2)))\n",
    "# print('PCR score: ' + str(np.round(PCR_score,2)))\n",
    "\n",
    "# # Parity Plot\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4057ffd",
   "metadata": {},
   "source": [
    "This added step has two benefits:\n",
    "\n",
    "* The features become uncorrelated between them.\n",
    "* The dimensionality of the feature matrix can be reduced.\n",
    "\n",
    "\n",
    "- **To do:**\n",
    "    - Modify the number of PC scores used in the regression and:\n",
    "        - track the resulting R2 score.\n",
    "        - track the parity plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can test the regression with fewer features\n",
    "# q = ...\n",
    "# Z_train =  ...\n",
    "# Z_test  = ..=.\n",
    "\n",
    "# # Perform the regression and prediction\n",
    "# PCR_reg = ...\n",
    "# y_pred_PCR = ...\n",
    "\n",
    "# # Compare LS-PCR scores\n",
    "# PCR_score = ...\n",
    "\n",
    "# print('LS score: ' + str(np.round(LS_score,2)))\n",
    "# print('PCR score: ' + str(np.round(PCR_score,2)))\n",
    "\n",
    "# # Parity plot\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f89f56",
   "metadata": {},
   "source": [
    "## Comparison: LS-LassoCV-RidgeCV-PCR\n",
    "\n",
    "- Parity Plot\n",
    "- Coefficients\n",
    "- Test results\n",
    "\n",
    "-**To do**: uncomment the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09f78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coefficients Plot\n",
    "# plt.figure(figsize=(7,3))\n",
    "# plt.scatter(range(n_coef),            LS_reg.coef_     , label='LS'      , s=100, alpha=1)\n",
    "# plt.scatter(range(n_coef),            RidgeCV_reg.coef_, label='RidgeCV' , s=100, alpha=0.6)\n",
    "# plt.scatter(range(n_coef),            LassoCV_reg.coef_, label='LassoCV' , s=100, alpha=0.6)\n",
    "# plt.scatter(range(len(PCR_reg.coef_)),PCR_reg.coef_    , label='PCR'     , s=100, alpha=0.6)\n",
    "\n",
    "# plt.grid(color='k', linestyle='-', alpha=0.2)\n",
    "# plt.xlabel('i')\n",
    "# plt.ylabel(r'$\\beta_i$')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parity Plot\n",
    "# plt.figure(figsize=(7,3))\n",
    "# # plt.figure(figsize=(3,3))\n",
    "# plt.scatter(y_test, y_pred_LS     ,label='LS'       , s=100, alpha=1)\n",
    "# plt.scatter(y_test, y_pred_RidgeCV, label='RidgeCV' , s=100, alpha=0.6)\n",
    "# plt.scatter(y_test, y_pred_LassoCV, label='LassoCV' , s=100, alpha=0.6)\n",
    "# plt.scatter(y_test, y_pred_PCR    , label='PCR'     , s=100, alpha=0.6)\n",
    "\n",
    "# plt.plot(y_test, y_test, c='r', alpha=0.6, ls='--')\n",
    "# plt.xlim(y_test.min()-1, y_test.max()+1)\n",
    "# plt.ylim(y_test.min()-1, y_test.max()+1)\n",
    "# plt.xlabel('Observed log PSA')\n",
    "# plt.ylabel('Predicted log PSA')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db102c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the prediction and test on the measurement-target space\n",
    "# Nmeas = 4\n",
    "# fig, axs = plt.subplots(1,Nmeas, figsize=(Nmeas*3,3))\n",
    "# plt.suptitle('Pred and test')\n",
    "# for i in range(Nmeas):\n",
    "#     axs[i].scatter(X_std_test[:,i], y_test,    c='k' , alpha=1 , label='test')\n",
    "#     axs[i].scatter(X_std_test[:,i], y_pred_LS        , alpha=0.5, label='LS')\n",
    "#     axs[i].scatter(X_std_test[:,i], y_pred_RidgeCV   , alpha=0.5, label='RidgeCV')\n",
    "#     axs[i].scatter(X_std_test[:,i], y_pred_LassoCV   , alpha=0.5, label='LassoCV')\n",
    "#     axs[i].scatter(X_std_test[:,i], y_pred_PCR       , alpha=0.5, label='PCR')\n",
    "#     axs[i].set_xlabel(str(X_name[i] + '$_{std}$') )\n",
    "#     axs[i].set_ylabel(y_name)\n",
    "# axs[Nmeas-1].legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Scores\n",
    "# print('LS       score: ' + str(np.round(LS_score,4)))\n",
    "# print('RidgeCV  score: ' + str(np.round(RidgeCV_score,4)))\n",
    "# print('LassoCV  score: ' + str(np.round(LassoCV_score,2)))\n",
    "# print('PCR      score: ' + str(np.round(PCR_score,2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
